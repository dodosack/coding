{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Newton's method<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#What-do-we-need-Newton's-method-for?\" data-toc-modified-id=\"What-do-we-need-Newton's-method-for?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>What do we need Newton's method for?</a></span></li><li><span><a href=\"#How-does-Newton's-method-work?\" data-toc-modified-id=\"How-does-Newton's-method-work?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>How does Newton's method work?</a></span></li><li><span><a href=\"#When-to-stop-the-iteration?\" data-toc-modified-id=\"When-to-stop-the-iteration?-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>When to stop the iteration?</a></span></li><li><span><a href=\"#How-to-extend-to-systems-of-equations\" data-toc-modified-id=\"How-to-extend-to-systems-of-equations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>How to extend to systems of equations</a></span></li><li><span><a href=\"#What-are-the-limitations?\" data-toc-modified-id=\"What-are-the-limitations?-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>What are the limitations?</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What should I know before I start?\n",
    " - How to use loops and control statements in Python.  \n",
    " - How to bulid a vector and a matrix with `np.array()`.\n",
    " - How to solve a linear system with `linalg.solve()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## What do we need Newton's method for?\n",
    "In scientific and technical applications, the functions are usually so complex that an exact calculation of the zeros by formulas is only possible in very simple cases.\n",
    "Therefore, many practical problems have to be solved by numerical approximation methods.\n",
    "The best-known approximation method for determining the roots of a function goes back to the English mathematician Isaac Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How does Newton's method work?\n",
    "Newton's method, or more precisely Newton's root finding method, determines approximations to the roots of a real function $f$:\n",
    "\n",
    "$$\n",
    "    f(x) = 0.\n",
    "$$\n",
    "\n",
    "It starts with an initial guess $\\tilde{x}_0$ and produces successively better approximations:\n",
    "\n",
    "$$\n",
    "\\tilde{x}_0, \\, \\tilde{x}_1, \\, \\tilde{x}_2, \\, \\ldots, \\tilde{x}_n.  \n",
    "$$\n",
    "\n",
    "The basic idea is based on linearizing the function at suitable points by the tangent and then determining the point of intersection of the tangent with the $x$-axis.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/wuyiv8059c414ci/newton.jpg?raw=1\"/>\n",
    "\n",
    "From the graphical procedure, corresponding formulas for the iteration can be derived.\n",
    "The equation of the tangent at the initial guess $\\tilde x_0$ is given by\n",
    "\n",
    "$$\n",
    "y = f(\\tilde x_0) + f'(\\tilde x_0)(x - \\tilde x_0).\n",
    "$$\n",
    "\n",
    "The intersection condition with the $x$-axis results in: \n",
    "\n",
    "$$\n",
    "x = \\tilde x_0 - \\frac{f(\\tilde x_0)}{f'(\\tilde x_0)}.\n",
    "$$\n",
    "\n",
    "This $x$-value is now selected as the new initial guess $\\tilde x_1$ for the next step.\n",
    "If the procedure is succesful, we will approach a root step by step.\n",
    "\n",
    "In summary, we get the following algorithm:\n",
    "1. Find a good initial guess $\\tilde x_0$.\n",
    "2. Calculate a sequence of approximations: \n",
    "$$\n",
    "\\tilde x_{k+1} = \\tilde x_k - \\frac{f(\\tilde x_k)}{f'(\\tilde x_k)}, \\quad k = 0,1,2,\\ldots, n-1.\n",
    "$$\n",
    "3. Repeat the process until a sufficiently precise value is reached. \n",
    "\n",
    "As a simple example lets consider:\n",
    "\n",
    "$$\n",
    "f(x) = \\mbox{e}^x-x-2.\n",
    "$$\n",
    "\n",
    "With the initial guess $\\tilde{x}_0 = 1$ we get:\n",
    "\n",
    "$$\n",
    "\\tilde{x}_1 = 1 - \\frac{\\mbox{e}^1-1-2}{\\mbox{e}^1-1} \\approx 1.163953413738653\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 =  1.163953413738653\n",
      "x_2 =  1.1464211850430086\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_0 = 1.0\n",
    "f = np.exp(x_0)-x_0-2.0\n",
    "fp = np.exp(x_0)-1\n",
    "x_1 = x_0 - f/fp\n",
    "print('x_1 = ',x_1)\n",
    "f = np.exp(x_1)-x_1-2.0\n",
    "fp = np.exp(x_1)-1\n",
    "x_2 = x_1 - f/fp\n",
    "print('x_2 = ',x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## When to stop the iteration?\n",
    "There are several possible variants to determine a condition to abort the iteration, .\n",
    "If two successive approximate values $\\tilde x_k$ and $\\tilde x_{k+1}$ are close enough to each other, we can abort the iteration.\n",
    "It is therefor clever to consider the difference of two successive values when implementing the iteration:\n",
    "\n",
    "$$\n",
    "dx_{k+1} = \\tilde x_{k+1} - \\tilde x_k = - \\frac{f(\\tilde x_k)}{f'(\\tilde x_k)}\n",
    "$$\n",
    "\n",
    "We abort the iteration if the $x$-values differ by less than the machine accuracy $\\epsilon$.\n",
    "This has the additional advantage that we can overwrite the old $x$-value with the new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.163953413738653\n",
      "1.1464211850430086\n",
      "1.1461932587044987\n",
      "1.1461932206205836\n",
      "1.1461932206205827\n",
      "1.1461932206205827\n"
     ]
    }
   ],
   "source": [
    "x = 1.0\n",
    "while True:\n",
    "    f = np.exp(x)-x-2.0\n",
    "    fp = np.exp(x)-1\n",
    "    dx = - f/fp\n",
    "    x = x + dx\n",
    "    print(x)\n",
    "    if abs(dx) < np.finfo(float).eps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above implementation has one important drawback.\n",
    "It may end up in an enless loop.\n",
    "Therefore we improve it by a slight modification and limit the iterations to a maximal number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.163953413738653\n",
      "1.1464211850430086\n",
      "1.1461932587044987\n",
      "1.1461932206205836\n",
      "1.1461932206205827\n",
      "1.1461932206205827\n"
     ]
    }
   ],
   "source": [
    "x = 1.0\n",
    "for k in range(10):\n",
    "    f = np.exp(x)-x-2.0\n",
    "    fp = np.exp(x)-1\n",
    "    dx = - f/fp\n",
    "    x = x + dx\n",
    "    print(x)\n",
    "    if abs(dx) < np.finfo(float).eps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Alternatively, the procedure can be stopped when the amount of the function value $f(\\tilde x_k)$ has become small enough.\n",
    "In practice, several termination conditions are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to extend to systems of equations\n",
    "One may also use Newton's method to solve systems of nonlinear equations.\n",
    "We focus here on two functions $f_1$ and $f_2$ with two variables $x_1$ and $x_2$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "    f_1(x_1,x_2) & = & 0, \\\\\n",
    "    f_2(x_1,x_2) & = & 0. \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The general case with more than two functions and variables is analogous.\n",
    "\n",
    "Using vector notation\n",
    "\n",
    "$$\n",
    "x = \\left(\n",
    "\\begin{array}{c}\n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "\\end{array}\n",
    "\\right),\n",
    "\\quad\n",
    "f(x) = \\left(\n",
    "\\begin{array}{c}\n",
    "    f_1(x_1,x_2) \\\\\n",
    "    f_2(x_1,x_2) \\\\\n",
    "\\end{array}\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "the problem can then be formulated as:\n",
    "\n",
    "$$\n",
    "f(x) = 0.\n",
    "$$\n",
    "\n",
    "To apply Newton's iteration formula:\n",
    "\n",
    "$$\n",
    "dx_{k+1} = - \\frac{f(\\tilde x_k)}{f'(\\tilde x_k)},\n",
    "$$\n",
    "\n",
    "we need to clarify the meaning of the derivative $f'$.\n",
    "Clearly, for a function with more than one varaible we have to use partial derivatives.\n",
    "Since we have more than one function, we bring them together in a matrix, the so called Jacobian matrix:\n",
    "\n",
    "$$\n",
    "J(x_1,x_2) = \\left(\n",
    "\\begin{array}{cc}\n",
    "    \\frac{\\displaystyle \\partial f_1(x_1,x_2)}{\\displaystyle \\partial \\, x_1} &\n",
    "    \\frac{\\displaystyle \\partial f_1(x_1,x_2)}{\\displaystyle \\partial \\, x_2} \\\\\n",
    "    \\frac{\\displaystyle \\partial f_2(x_1,x_2)}{\\displaystyle \\partial \\, x_1} &\n",
    "    \\frac{\\displaystyle \\partial f_2(x_1,x_2)}{\\displaystyle \\partial \\, x_2}\n",
    "\\end{array}\n",
    "\\right) \n",
    "$$\n",
    "\n",
    "This leads us to the next problem: how do we divide by a matrix?\n",
    "The answer is obvious if we rewrite Newton's iteration formula:\n",
    "\n",
    "$$\n",
    "dx_{k+1} = - \\left(f'(\\tilde x_k)\\right)^{-1} \\, f(\\tilde x_k).\n",
    "$$\n",
    "\n",
    "This means that dividing by a matrix is equivalent to multiplying by the inverse matrix.\n",
    "Multiplying with the inverse matrix means nothing else than solving a system of linear equations:\n",
    "\n",
    "$$\n",
    "dx_{k+1} = - \\left(f'(\\tilde x_k)\\right)^{-1} \\, f(\\tilde x_k)\n",
    "\\quad \\Longrightarrow \\quad\n",
    "f'(\\tilde x_k) \\, dx_{k+1} = - f(\\tilde x_k).\n",
    "$$\n",
    "\n",
    "We will now look at this in detail for the following example:\n",
    "\n",
    "$$\n",
    "f(x,y) = \\left(\n",
    "\\begin{array}{c}\n",
    "    \\mbox{e}^x + y - 2 \\\\\n",
    "    x^2 + 2 \\, y^2 - 6 \\\\\n",
    "\\end{array}\n",
    "\\right) = 0.\n",
    "$$\n",
    "\n",
    "The Jacobian matrix looks like this:\n",
    "$$\n",
    "J(x,y) = \\left(\n",
    "\\begin{array}{cc}\n",
    "    \\mbox{e}^x & 1 \\\\\n",
    "    2 \\, x & 4 \\, y \\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "We avoid determining a formula for the inverse of the Jacobian matrix.\n",
    "We use Python to calculate the inverse of the Jacobian matrix.\n",
    "\n",
    "Geometrically, each individual equation can be represented by a curve in the $x$-$y$-plane.\n",
    "The points of intersection of these curves in turn are the solutions we seek. \n",
    "As we can see from the figure there are two solutions.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/c4jrxxlknszrelb/newton2.jpg?raw=1\"/>\n",
    "\n",
    "Now we are well prepaired to implement Newton's iteration for this example in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.47534204 -1.51232898]\n",
      "[ 1.27281682 -1.48698329]\n",
      "[ 1.25005406 -1.48961351]\n",
      "[ 1.24979642 -1.48963233]\n",
      "[ 1.24979638 -1.48963234]\n",
      "[ 1.24979638 -1.48963234]\n",
      "[ 1.24979638 -1.48963234]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2.0,-2.0])\n",
    "for k in range(10):\n",
    "    f = np.array( [np.exp(x[0])+x[1]-2.0, x[0]**2+2*x[1]**2-6.0] )\n",
    "    J = np.array( [ [np.exp(x[0]),1], [2*x[0],4*x[1]] ])\n",
    "    dx = np.linalg.solve(J,-f)\n",
    "    x = x + dx\n",
    "    print(x)\n",
    "    if max(abs(dx)) < np.finfo(float).eps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we use `linalg.solve()` in order to solve the linear system of equations.\n",
    "Since $dx$ is a vector we use `max()` to ensure that each coordinate is sufficently accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## What are the limitations?\n",
    "As a rule, Newton's approximation method converges very quickly against a solution.\n",
    "\n",
    "However, the following things should be noted:\n",
    " - In case of multiple roots, the method converges slowly or not at all.\n",
    " - Starting from a certain initial guess, Newton's method finds at most one solution. To determine more than one solution, the iteration can be performed with different initial guesses.\n",
    " - In some situations Newton's iteration does not converge towards a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Conclusion\n",
    " - Newton's method is a root-finding algorithm which produces a sequence of approximations:\n",
    " \n",
    "$$\n",
    "\\tilde{x}_0, \\, \\tilde{x}_1, \\, \\tilde{x}_2, \\, \\ldots  \n",
    "$$\n",
    "\n",
    " - It can be used for a single equation or for a system of equations.\n",
    " - It needs an initial guess $\\tilde{x}_0$, the closer to the root, the better.\n",
    " - The iteration formula is\n",
    "\n",
    "$$\n",
    " \\tilde x_{k+1} = \\tilde x_k - \\frac{f(\\tilde x_k)}{f'(\\tilde x_k)}, \\quad\n",
    " k = 0,1,2,\\ldots\n",
    "$$\n",
    "\n",
    " - For implementations it is clever to consider the difference of two successive values and stop if $dx_{k+1}$ is sufficient small:\n",
    "\n",
    "$$\n",
    "dx_{k+1} = - \\frac{f(\\tilde x_k)}{f'(\\tilde x_k)} \n",
    "\\quad \\Longrightarrow \\quad\n",
    "\\tilde x_{k+1} = \\tilde x_k + dx_{k+1}\n",
    "$$\n",
    "\n",
    " - Generalization to nonlinear systems of equations is based on vector and matrix notation. It envolves the Jacobian matrix and solving a linear system with `linalg.solve()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Did you get it?\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Task 1</b>\n",
    "\n",
    "Apply Newton's method to the equation\n",
    "\n",
    "$$\n",
    "\\cos(x) - x = 0.    \n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.5\n",
    "for k in range(10):\n",
    "    f = np.cos(x)-x\n",
    "    fp = -np.sin(x)-1\n",
    "    dx = -f/fp\n",
    "    x = x + dx\n",
    "    print('x = ',x)\n",
    "    if abs(dx) < np.finfo(float).eps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Task 2</b>\n",
    "\n",
    "Apply Newton's method to the system of equations\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\sin(x) - y & = & 0, \\\\\n",
    "x^2 + y^4 -1 & = & 0.\n",
    "\\end{array}\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.0,1.0])\n",
    "for k in range(10):\n",
    "    f = np.array([np.sin(x[0])-x[1],x[0]**2+x[1]**4-1])\n",
    "    J = np.array([[np.cos(x[0]),-1.0],[2*x[0],4*x[1]**3]])\n",
    "    dx = np.linalg.solve(J,-f)\n",
    "    x = x + dx\n",
    "    print('x = ',x)\n",
    "    if max(abs(dx)) < np.finfo(float).eps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature\n",
    "- https://youtu.be/dP6kakuaPps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Newton's method",
   "title_sidebar": "Newton's method",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
