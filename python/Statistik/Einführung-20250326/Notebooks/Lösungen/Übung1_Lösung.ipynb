{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d4ce6a",
   "metadata": {},
   "source": [
    "# Einführung Statistiklabor\n",
    "\n",
    "# Beispielaufgabe 1 - Schulnoten\n",
    "\n",
    "Lesen Sie die txt-Datei mit den Schulnoten ein und lassen Sie sich diese als Pandas-Dataframework ausgeben.\n",
    "Anschließend sollen die **Häufigkeiten der erreichten Noten mithilfe eines Säulendiagramms** dargestellt sowie der *Mittelwert*, die *Standardabweichung*, die *Varianz* und der *Median* sowie die *Spannweite* ausgegeben werden. \n",
    "\n",
    "Die Formel für den Mittelwert zum Beispiel lautet:\n",
    "$$\\bar x = \\frac{1}{n}\\sum_{i=1}^{n} x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12912567",
   "metadata": {},
   "source": [
    "## 1. Einlesen der Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d443150a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\einf_b1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5b1982747586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m#Bibliothek pandas zum erstellen von Dataframeworks (zur weiteren Verarbeitung)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m data = pd.read_csv(r'.\\einf_b1.txt', # r für Rohstring, damit '\\' als Zeichen anerkannt wird\n\u001b[0m\u001b[0;32m      4\u001b[0m                      \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m        \u001b[1;31m# Separator im txt-file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# NA (not a number) --> fehlende Werte, gibt es in diesem Dokument eigt keine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\einf_b1.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #Bibliothek pandas zum erstellen von Dataframeworks (zur weiteren Verarbeitung)\n",
    "\n",
    "data = pd.read_csv(r'.\\einf_b1.txt', # r für Rohstring, damit '\\' als Zeichen anerkannt wird\n",
    "                     sep=' ',        # Separator im txt-file\n",
    "                     na_values='.',  # NA (not a number) --> fehlende Werte, gibt es in diesem Dokument eigt keine\n",
    "                     header=None,    # gibt keine Überschriften im File, erste Zeile = erster Wert\n",
    "                     decimal=',',    # im File sind Dezimalstellen über Komma getrennt, Python braucht Punkte\n",
    "                     names=['Nr.','Punkte', 'Note']) # neue Spaltenüberschriften werden vergeben\n",
    "\n",
    "pd.set_option('display.max_rows',None) # zeigt immer alle eingelesenen Daten\n",
    "data                                   # zeigt das komplette Dataframework / die Tabelle\n",
    "#data.head(5)                          # zeigt nur die ersten 5 Einträge \n",
    "#data.at[1,'Punkte'] #=90              # Zugriff auf den Wert in der zweiten Zeile (index=1) und zweiten Spalte ('Punkte')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12f038",
   "metadata": {},
   "source": [
    "## 2. Daten bereinigen\n",
    "In der 11. Zeile (index = 10) scheinen ungültige Daten vorzuliegen. Diese sollen aus dem Datensatz (mit `dataframe.drop()`) gelöscht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([10], axis = 0)    # axis = gibt an, ob Zeile (=0) oder Spalte (=1) gelöscht wird \n",
    "data = data.reset_index()           # index zurücksetzen, allerdings wird alter Index noch angezeigt\n",
    "data = data.drop('index', axis = 1) # Spalte mit altem Index löschen\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915b89f",
   "metadata": {},
   "source": [
    "## 3. Säulendiagramm der Häufigkeiten erstellen\n",
    "\n",
    "### 3.1 Schulnoten-\"klassen\" einführen\n",
    "Jede Dezimalnote kann einer eindeutigen Schulnotenklasse wie *sehr gut*, *gut*, ... und *ungenügend* zugeordnet werden. \n",
    "Die Trennung erfolgt immer bei $x,3$. Sodass z.B. 2,3 noch zur Gruppe gut gehört. **Aber:** Ab 4,0 ist die Zuordnung allgemein ungenügend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "notenGrenzen = [0, 1.3, 2.3, 3.3, 4.0, 6.0]   \n",
    "# - immer eine Klasse weniger als eine Grenze (0,1.3] -> halboffenes Intervall einschließlich 1.3\n",
    "notenKlassen = ['sehr gut', 'gut', 'befriedigend', 'ausreichend', 'ungenügend']\n",
    "\n",
    "# die neuen Klassen den jeweiligen Schulnoten zuordnen und dem Dataframe hinzufügen\n",
    "neue_noten = pd.cut(data['Note'], notenGrenzen, labels=notenKlassen) \n",
    "data['Schulnoten'] = neue_noten # Dataframe kann durch Bezeichnung einer neuen Spalte erweitert werden\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6244de",
   "metadata": {},
   "source": [
    "#### 3.1.1 Zusatz: Daten filtern\n",
    "Hier werden zwei Ansätze vorgestellt, um ein neues Dataframe mit nur bestimmten Zeilen aus dem alten Datensatz zu erzeugen.\n",
    "1. Daten über den Zeilenindex filtern und in einem neuen Dataframe ablegen.\n",
    "2. Daten über Spaltenwerte/-eigenschaften filtern und abspeichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559cddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zu 1. über for-Schleife mit Index-array\n",
    "index = [3,5,7,9,27] # Liste mit Indices die herausgefiltert werden sollen \n",
    "new_data = pd.DataFrame() # ein leeres Dataframe anlegen, in dem die entsprechenden Datenzeilen abgespeichert werden sollen\n",
    "\n",
    "# mithilfe der for-Schleife über Liste mit Indices iterieren\n",
    "for i in index:\n",
    "    new_data = pd.concat([new_data, data.loc[i].to_frame().T],axis=0) # über pd.concat() Dataframes aneinanderhängen\n",
    "    # pd.concat([Dataframes die zusammengefügt werden], axis=0(Zeilenweise anhängen))\n",
    "    # data.loc[index] erzeugt pandas.Series mit Werten der entsprechenden Zeile\n",
    "    # pd.Series.to_frame() --> wandet Series in Dataframe um\n",
    "    # pd.Dataframe().T --> transponiert Dataframe\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zu 2. über boolean masking\n",
    "mask = data['Note'] >= 2.7 # neue Serie mit bool-Werten für Noten schlechter 2.3\n",
    "data[mask] # mithilfe bool-Serie kann Dataframe schnell gefiltert werden (nur Zeilen mit True-Maske werden angezeigt)\n",
    "#data[mask & (data['Note']<=4.0)] # über &-Operator können zwei  \n",
    "\n",
    "#grade_3 = data[data['Schulnoten']=='befriedigend'] # funktioniert auch mit strings\n",
    "#grade_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f811cc2",
   "metadata": {},
   "source": [
    "### 3.2 Häufigkeiten bestimmen\n",
    "Mithilfe der Pandas-Funktion `value_counts()` kann ganz leicht die absolute Häufigkeit der jeweiligen Note $H_n(Note)$ bestimmt werden.\n",
    "\n",
    "*z.B.: $H_n(gut) = 20$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf17ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hf = pd.value_counts(data['Schulnoten'], sort=False).rename_axis('Schulnoten').reset_index(name='Häufigkeit')\n",
    "            #value_counts(zu zählende Daten , ob Daten nach Häufigkeit sortiert werden sollen) \n",
    "                                                       ##.rename_axis() ('Spalten-')Bezeichnung der gezählten Eigenschaften\n",
    "                                                       ##.reset_index() Anzahl der Eigenschaften(name=Spaltenbeschriftung)\n",
    "\n",
    "data_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739cfe02",
   "metadata": {},
   "source": [
    "#### Die relative Häufigkeit\n",
    "$h_n = \\frac{H_n(Note)}{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data_hf['Häufigkeit'].sum() # Über.sum-Methode die Grundgesamtheit 'n' bestimmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1098cc6",
   "metadata": {},
   "source": [
    "*optionaler Zusatz: Die Summen der Spalten in neuer Zeile mit ausgeben lassen:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aab0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# die Summen der Häufigkeit mit Ausgeben lassen --> neue Zeile wird automatisch erstellt, da erstmals referenziert wird\n",
    "data_hf.loc['Summe']=data_hf['Häufigkeit'].sum() # über .loc[] können ganze Spalten oder Zeilen addressiert werden\n",
    "data_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6180c1",
   "metadata": {},
   "source": [
    "Relative Häufigkeit in Prozent [%] bestimmen (vgl. obere Formel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hf['rel. Häufigkeit in %'] = (data_hf['Häufigkeit'] / n * 100).round(2) # neue Spalte für h_n wird durch Nennung angelegt\n",
    "data_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac08a1b",
   "metadata": {},
   "source": [
    "### 3.3 Säulendiagramm erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc26d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(data_hf['Schulnoten'][0:5], data_hf['Häufigkeit'][0:5], #plt.bar(x-Achse, y-Achse, weitere Eigenschaften/Attribute)\n",
    "        width=0.9, color='darkblue') \n",
    "\n",
    "plt.xlabel('Schulnoten')                                        # Beschriftung der x-Achse\n",
    "plt.ylabel('Häufigkeit')                                        # Beschriftung der y-Achse\n",
    "plt.title('Verteilung der Schulnoten im letzten Schuljahr')     # Titel oberhalb des Diagramms\n",
    "plt.show()                                                      # optional in Notebooks: Anzeigen des Diagramms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a36bc0",
   "metadata": {},
   "source": [
    "#### Ergänzung: Zwei Säulendiagramme in einer Figure + Beschriftung der Säulen hinzufügen\n",
    "(am Beispiel der relativen Häufigkeit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # mithilfe von numpy können unter anderem arrays erzeugt werden\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xAxis = np.arange(len(data_hf['Schulnoten'][0:5])) # es wird ein numpy-Array erzeugt\n",
    "\n",
    "plt.bar(xAxis - 0.2, data_hf['Häufigkeit'][0:5], width=0.4, color='darkblue', label='abs. Häufigkeit')\n",
    "plt.bar(xAxis + 0.2, data_hf['rel. Häufigkeit in %'][0:5], width=0.4, color='orange', label='rel. Häufigkeit')\n",
    "\n",
    "plt.xticks(xAxis, data_hf['Schulnoten'][0:5])\n",
    "plt.xlabel('Schulnoten')\n",
    "plt.ylabel('Häufigkeiten')\n",
    "plt.title('Verteilung der Schulnoten im letzten Schuljahr')\n",
    "plt.legend()\n",
    "\n",
    "# Beschriftung der einzelnen Säulen hinzufügen\n",
    "for bar in ax.patches:\n",
    "    bar_height = bar.get_height()\n",
    "    ax.annotate(text = bar_height,\n",
    "                xy = (bar.get_x() + bar.get_width() / 2, bar_height+1),\n",
    "                ha='center', va='center'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be2ee4",
   "metadata": {},
   "source": [
    "## 4. Statistische Angaben ausgeben\n",
    "Für Mittelwert, Standardabweichung, Varianz und Median können vorgefertigte Methoden aufgerufen werden.<br>\n",
    "Die Spannweite wird bestimmt, indem der kleinste Wert vom größten abgezogen wird. Zur Bestimmung dieser beiden Werte können auch wieder vorgefertigte Methoden verwendet werden.\n",
    "\n",
    "Die tabellarische Ausgabe erfolgt hier beispielhaft über ein Dataframe mit einem dictionaire `kennzahlen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict anlegen mit den Kennzahlen für die erreichten Punkte und entsprechenden Noten\n",
    "kennzahlen = {'Punkte': [data['Punkte'].mean(), \n",
    "                         data['Punkte'].var(), \n",
    "                         data['Punkte'].std(), \n",
    "                         data['Punkte'].median(), \n",
    "                         data['Punkte'].max() - data['Punkte'].min()],\n",
    "              'Noten': [data['Note'].mean(), \n",
    "                        data['Note'].var(), \n",
    "                        data['Note'].std(), \n",
    "                        data['Note'].median(), \n",
    "                        data['Note'].max() - data['Note'].min()]\n",
    "             }\n",
    "\n",
    "# Umwandlung dict in pd-Dataframe mit neuer Zeilen-Indexierung (statt vorheriger Durchnummerierung)\n",
    "key_frame = pd.DataFrame(kennzahlen, index = ['Mittelwert', 'emp. Varianz', 'emp. Std.-Abw.', 'emp. Median', 'Spannweite'])\n",
    "key_frame.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0a831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
